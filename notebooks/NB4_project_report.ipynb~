{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Google Trends and Stock Prices\n",
      "\n",
      "Jordeen Chang, Anshuman Dewangan, Anirudh Kilambi, Hiroto Udagawa  \n",
      "STAT 133  \n",
      "Professor Benoit Dherin  \n",
      "4 May 2014\n",
      "\n",
      "###*Insert trends_logo.png\n",
      "###*Insert stocks_logo.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###Contributors\n",
      "\n",
      "* Anshuman Dewangan: Authored IPython Notebook from start to the end of Data Gathering section."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Introduction\n",
      "###*insert ben_0.jpg  \n",
      "You are Luc L'Argent, an investment banker who is looking to beat the stock market. You just took STAT 133 with Professor Dherin (who looks weirdly similar to you) and want to use statistical programming to develop a stock trading algorithm. However, you don't know about Time Series, Markov Chains, or other advanced trading tactics. What should you do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Luckily, you run across the following research paper:  \n",
      "###*Insert research_paper.jpg\n",
      "The paper investigates the extent to which investor opinions posted on social media predict future stock returns. The following quote catches your eye...\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1807265"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###\"A trading strategy based on social media sentiment could generate significant trading profits.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This gives you a great idea: What if you could use Google search data to predict future stock returns? You call your friends Bob, Marthieux, and Isabel from your STAT 133 class to do a data analysis project based on the idea."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##The Idea\n",
      "\n",
      "We want to analyze the relationship between Google Trends search data and stock prices for the companies in the Dow Jones Industrial Average, a list of 30 top U.S. companies, and the S&P500, a list of 500 top U.S. companies. We will look for three main trends:\n",
      "\n",
      "1. Relationship between Google Trends data for the company name/ticker (\u201cApple\u201d or \u201cAAPL\u201d) and the stock price.\n",
      "2. Relationship between Google Trends data for positive terms related to the company name/ticker (\u201cBuy Apple\u201d) and the stock price.\n",
      "3. Relationship between Google Trends data for negative terms related to the company name/ticker (\u201cSell Apple\u201d) and the stock price.\n",
      "\n",
      "Finally, we will make a simple stock trading algorithm based on these trends and see how a hypothetical portfolio would function on historical data. Excited? Great! Let's walk through the steps needed to complete the project, beginning with data gathering."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - Google Trends Website\n",
      "\n",
      "You call your friends over for help, but they have no idea where to begin. Let's see how we can get Google search data for a particular company, \"Apple.\" We'll Google \"google search data\" and see what we get!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "###*Insert google_search_data.jpg\n",
      "\n",
      "Ok, the first search result, \"Google Trends\" seems promising. Let's check it out!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "###*Insert google_trends.jpg\n",
      "\n",
      "Cool! Looks like we can enter different search terms and get some Google search data. Let's try it out for Apple."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "##*Insert download_csv.jpg\n",
      "\n",
      "Entering \"apple\" into the search box results in a graph of the search data over time. This is exactly what we want! And it seems like we can just \"Download as csv\" as well, making data gathering a breeze.  \n",
      "\n",
      "There's a lot of spikes and dips in the data; hopefully the variability in the search data will match the changes in Apple's stock price. We'll worry about that in the data analysis. But first, we have to pull the data in our iPython Notebook."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - Search Queries\n",
      "\n",
      "We want to get search data for a lot of different queries, so let's organize the information. First, we can manually create two csv files, \"SP500.csv\" and \"DowJones.csv,\" with the list of companies in the S&P500 and Dow Jones Industrial Average from Yahoo Finance with two columns: \"Company\", \"Ticker.\" This will allow us to easily generate queries for each company."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow"le\n",
      "6. Sell Apple"
     ]
    },
    { {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },: {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Queries can be categorized in many different ways:\n",
      "\n",
      "1. Company name\n",
      "2. Ticker symbol\n",
      "3. \"Buy\" + ticker symbol\n",
      "4. \"Sell\" + ticker symbol\n",
      "5. \"Buy\" + company name\n",
      "6. \"Sell\" + company name\n",
      "\n",
      "For example, Apple will have six different queries:\n",
      "\n",
      "1. Apple\n",
      "2. AAPL\n",
      "3. Buy AAPL\n",
      "4. Sell AAPL\n",
      "5. Buy Apple\n",
      "6. Sell Apple"
     ]
    },
    { {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replac"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }e(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replac"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }e(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replac"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }e(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replac"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }e(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmag
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },ic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition:ot some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     }, Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }otective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }    "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "tadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "In this notebook, you'll sumarize your finding for the class presentation. \n",
      "\n",
      "\n",
      "The class presentation will use this notebook in slide mode, as I do during lecture time.\n",
      "\n",
      "You'll need to download the following [zip file](https://github.com/fperez/nb-slideshow-template/archive/master.zip), unzip it, and run the following notebook <code>install-support.ipynb</code> to install the slide capabilities.\n",
      "\n",
      "The notebook <code>notebook-slideshow-example.ipynb</code> will give you examples on how to use slides within the iPython notebook.  \n",
      "\n",
      "You should also write this notebook so that you can convert it nicely into a pdf document using the commands\n",
      "\n",
      "    ipython nbconvert NB4_report.pynb --to latex\n",
      "    pdflatex NB4_report.tex\n",
      "    \n",
      "See [here](http://ipython.org/ipython-doc/rel-1.0.0/interactive/nbconvert.html) for further references on how to do that. \n",
      "\n",
      "In this notebook, you'll\n",
      "\n",
      "* describe your problem as stated in the propectus \n",
      " \n",
      " \n",
      "* comment on your data sources, on their format, on the difficulties to get them\n",
      "\n",
      "\n",
      "* present the main challenge you encountered\n",
      "\n",
      "\n",
      "* present your finding in the form of expresive graphics\n",
      "\n",
      "Be sure to include an introduction section motivating your visualizations, with a description of the substantive context and why it is interesting.\n",
      "\n",
      "\n",
      "Cite the source of the data and any other references that you used in carrying out your project.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Team members responsible for this notebook:\n",
      "\n",
      "List the team members contributing to this notebook, along with their responsabilities:\n",
      "\n",
      "* team member 1 **name**: team member 1 **responsabilities**\n",
      "* team member 2 **name**: team member 2 **responsabilities**\n",
      "* etc.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Problem\n",
      "\n",
      "Our group will examine the relationship between Google Trends (Google web search data) and stock prices of large companies namely in the S&P500.\n",
      "\n",
      "First, we will determine if there is a correlation between search data for the company name/ticker (\u201cApple\u201d or \u201cAAPL\u201d) and the stock price. \n",
      "\n",
      "Second, we will determine if there is a correlation between search data for positive terms related to the company name/ticker (\u201cBuy AAPL\u201d) and the stock price. \n",
      "\n",
      "Third, we will determine if there is a correlation between search data for negative terms related to the company name/ticker (\u201cSell AAPL\u201d) and the stock price. \n",
      "\n",
      "Finally, we will use this information to see if we can make a simple trading algorithm based on trends in the Google search data and see how a hypothetical portfolio would function on historical data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Sources\n",
      "\n",
      "We used Google Trends and Yahoo Finance as our sources of data. \n",
      "\n",
      "Google Trends data will be obtained from the Google Trends website (http://www.google.com/trends/explore#cmpt=q). Although there is a \u201cDownload as CSV\u201d option, we will need to find a way to find Google search data for a large number of search terms for a large number of stocks. One problem was that the Google trends data (how much it is searched) is normalized to a scale from 0-100 for every search. That means some of the values are 0, which we had to adjust for when we were cleaning the data. The Google Trends data was a csv, which made it easy to understand, but the hard part was getting all the data we needed. \n",
      "\n",
      "Therefore, we will need to create a script that can quickly repeat the process, or use an API that has already done so (http://techslides.com/hacking-the-google-trends-api/). \n",
      "\n",
      "Stock data is obtained from Yahoo Finance by creating a script or using a script available.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Luke Looks at Data\n",
      "\n",
      "After finally getting all the data he needs, Luke needs to see what data he is working with. He randomly opens up a couple of files to get a general sense of the data he has gathered.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "testing = read.csv(\"./data/raw/DowJones/3M Company_gtrends.csv\")\n",
      "testing2 = read.csv(\"./data/raw/DowJones_Modified/V_gtrends.csv\")\n",
      "testing3 = read.csv(\"./data/raw/SP500/sell BEN_gtrends.csv\")\n",
      "print(head(testing))\n",
      "print(head(testing2))\n",
      "print(head(testing3))\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "        Date X3M.Company Price\n",
        "1 2004-01-09           0    NA\n",
        "2 2004-01-16           0    NA\n",
        "3 2004-01-23         100    NA\n",
        "4 2004-01-30           0    NA\n",
        "5 2004-02-06           0 79.81\n",
        "6 2004-02-13           0 79.68\n",
        "        Date  V Price\n",
        "1 2004-01-09 35    NA\n",
        "2 2004-01-16 35    NA\n",
        "3 2004-01-23 35    NA\n",
        "4 2004-01-30 35    NA\n",
        "5 2004-02-06 34    NA\n",
        "6 2004-02-13 35    NA\n",
        "        Date sell.BEN Price\n",
        "1 2004-01-09        0    NA\n",
        "2 2004-01-16        0    NA\n",
        "3 2004-01-23        0    NA\n",
        "4 2004-01-30        0    NA\n",
        "5 2004-02-06        0 57.02\n",
        "6 2004-02-13        0 58.45\n",
        "$Date\n",
        "[1] \"factor\"\n",
        "\n",
        "$X3M.Company\n",
        "[1] \"integer\"\n",
        "\n",
        "$Price\n",
        "[1] \"numeric\"\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Luke Identifies the Problem\n",
      "\n",
      "Oh no! A lot of the data points do not have a price value which means those points are useless to him. And some of them have a value 0 for the number of Google Trends hits. That is going to affect his data analysis, so we must get rid of those points.\n",
      "\n",
      "He also wants all his data to be in the same format. The first file he tests seems to be okay."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "print(lapply(testing, class))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "$Date\n",
        "[1] \"factor\"\n",
        "\n",
        "$X3M.Company\n",
        "[1] \"integer\"\n",
        "\n",
        "$Price\n",
        "[1] \"numeric\"\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "He wants the first column to be a \"Date\", the second column to be an integer, since Google Trends data is always an integer, and the stock price to be a numeric. Thus we need to change all the data classes if they are not already in the correct format.\n",
      "\n",
      "We need to check every file in each of the three directories \"data/raw/DowJones\", \"data/raw/DowJones_Modified\", and \"data/raw/SP500\" and make sure they adhere to what Luke wants.\n",
      "\n",
      "Let's start coding!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Luke Cleans\n",
      "\n",
      "Luke, with his great R skills, comes up with a function that solves his problems. He runs his code on the three directories his raw data is stored in.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "cleanDow = function(fileName) {\n",
      "    stock = read.csv(paste(\"./data/raw/DowJones_Modified/\", fileName, sep = \"\"))\n",
      "    modes = data.frame(lapply(stock, class))\n",
      "    if (modes[1] != \"Date\") {\n",
      "        stock[,1] = as.Date(stock[,1], '%Y-%m-%d')\n",
      "    }\n",
      "    if (modes[2] != \"integer\") {\n",
      "        stock[,2] = as.integer(as.character(stock[,2]))\n",
      "    }\n",
      "    if (modes[3] != \"numeric\") {\n",
      "        stock[,3] = as.numeric(as.character(stock[,3]))\n",
      "    }\n",
      "    col = colnames(stock)\n",
      "    stock = stock[!is.na(stock[,1]) & !is.na(stock[,2]) & !is.na(stock[,3]) & stock[,2] != 0,]\n",
      "    write.csv(stock, file = paste(\"./data/cleaned/DowJones_Modified/\", fileName, sep = \"\"), row.names = FALSE)\n",
      "}"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Luke Looks at Clean Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Luke needs to check if his data follows his guidelines. He takes a look at the data he looked at earlier to see if his cleaning code works. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "cleanTest = read.csv(\"./data/cleaned/DowJones/3M Company_gtrends.csv\")\n",
      "cleanTest2 = read.csv(\"./data/cleaned/DowJones_Modified/V_gtrends.csv\")\n",
      "cleanTest3 = read.csv(\"./data/cleaned/SP500/sell BEN_gtrends.csv\")\n",
      "print(head(cleanTest))\n",
      "print(head(cleanTest2))\n",
      "print(head(cleanTest3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "        Date X3M.Company Price\n",
        "1 2004-04-02          84 81.78\n",
        "2 2004-04-16          90 83.73\n",
        "3 2004-04-23          93 87.90\n",
        "4 2004-04-30          62 86.48\n",
        "5 2004-05-07          66 84.43\n",
        "6 2004-05-14          70 83.81\n",
        "        Date  V Price\n",
        "1 2008-03-28 43 62.76\n",
        "2 2008-04-04 44 64.48\n",
        "3 2008-04-11 42 66.11\n",
        "4 2008-04-18 43 69.00\n",
        "5 2008-04-25 43 75.10\n",
        "6 2008-05-02 44 82.75\n",
        "        Date sell.BEN Price\n",
        "1 2008-03-14       83 90.45\n",
        "2 2009-02-27       63 45.80\n",
        "3 2009-03-06       61 38.66\n",
        "4 2009-03-13       61 49.04\n",
        "5 2009-03-20       61 47.09\n",
        "6 2009-03-27       61 54.20\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! Everything works! And now the data analysis can begin."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Main Challenges\n",
      "\n",
      "The most difficult part of the project was determining the correlation between two time series (Google Trends data and stock data). We have no experience in calculating this value and may need some guidance.\n",
      "\n",
      "Another cause of difficulty will be creating a trading algorithm for a hypothetical stock portfolio backtest. However, this part of the project will be out of personal interest. The goal is not to create a profitable stock trading algorithm, but to help us understand the relationship between Google Trends data and stock price data better.\n",
      "\n",
      "It is hard to draw a solid conclusion from this. Even if there is a strong correlation, we did not know whether the changing stock prices affected the google trends data or it was the other way around. It is unclear which caused what. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Visualization\n",
      "\n",
      "Our first graph shows the density of the correlations\n",
      "\n",
      "##Graph 1\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import Image \n",
      "Image(filename='./visualizations/plot1.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1xUdf7H8Q8XQQRE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\nQxHQAGAoAhoADEVAA4ChCGgAMNT/A9tR32F9wbkYAAAAAElFTkSuQmCC\n",
       "prompt_number": 4,
       "text": [
        "<IPython.core.display.Image at 0x103533390>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 2\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot2.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3dd1gUV8MF8LssVZqA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\nLQAAAABJRU5ErkJggg==\n",
       "prompt_number": 5,
       "text": [
        "<IPython.core.display.Image at 0x103533290>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Graph 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot3.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3dd3xUZb7H8d9kIAmQ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\nBgBDEdAAYCgCGgAMRUADgKEIaAAw1P8Du+4OhHayONsAAAAASUVORK5CYII=\n",
       "prompt_number": 6,
       "text": [
        "<IPython.core.display.Image at 0x103533310>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot4.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3dd1wT5+MH8CcQCMgW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\nqpQrhfSXAAAAAElFTkSuQmCC\n",
       "prompt_number": 7,
       "text": [
        "<IPython.core.display.Image at 0x103533590>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Graph 5\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot5.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deXhU9dn/8XtCFgIJ\nIRAgAdIEQwBLZKcCSgyLigphMQi19TEuQUSwKmIfflVBL2pdQGtdKoK1KPYRXIDIDtKI1VBJBYHn\nSSwSNAuELCQQAlnn/v0x0xDDJCRCznwH3q/Ly+vMOWfmvs+ZmU++fGezqaoAAMzj5e4GAACuEdAA\nYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCG\nIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOAoQhoADAUAQ0AhiKgAcBQBLQ7jB0rNpvs2CEikpoq\nEyZIRIT4+0uvXvL441JRcZ6rP/OM2Gzy2GP1l5vr+efFZpN27eTMGeeamhoJCBCbTYqKfsoNNkXd\nY69n50659VYJDZU2bSQmRp5/XsrLW6qNc91zj9hs8vrr9devXi0229n/OnWSUaPkiy9apAdVSU6W\nG26QDh0kKEiuuUbWrWuRQrV+wuNnyRKx2eTBB1usJ9ShsFhNjQYGqs2mJSW6dKmKqIh27qw+Ps7l\nOXPOcwuTJ6uIrlpVf7m5pk51Vly92rnmwAEV0R49fsqtNUXdY6+3ft48ZzMBAdqunXP59tudO7zy\nioroffe1VGOqOmiQiug//1l/vaOxkBDt21ejo513U5s2mp3d2K39hIarqjQx0XnggYHatq1z+aOP\nmn0sTdeUx0+9Y7n/fu3SRd9/vwW7wn8Q0Jaz29XXV3/1Kz16VP381N9fU1NVVc+c0d/9TkW0b9/z\n3EJ4uIrooUP1l5urRw9nBEyc6Fzz17+qiCYk/JRba4raY6/nxRdVRH/2M01J0aoqranRt95y9paf\nr6r6q1+piL79dks1Vlmpvr7q7a1nztTfNGqUiujSpc6L2dkaGqoiumRJYzf4Exp+7DEV0U6d9O9/\n16oqLS/X225TEb3hhmbcSHM15fHT0icfDSOg3SE+Xg8d0o8/dg5Xq6ud63Ny9JVX9IMPnBe//FIn\nTtTOnTUsTO+/X0+eVFXNy1MRDQ5Wu/1Hy81VWOgcCfbtqz4+WlSkqjp7toros8+qqr7zjg4apAEB\nGhioo0bp//2f6n+G2FFR+s472qePhobq0qW6c6defbW2basjRuiRI401X3vsdeXmakCAizHpo4/q\nPffo4cPas6czrEV00yb9/nsV0dBQ/ewzHT7cebpclnPs2aWLfvSRDhyobdvq+PF66pTz9g8f1mnT\ntFMnvfJKXb5cRXTgwPpnqabGOZxPSzu78t57VUQffLDBs1Sv4YZ2qysjQ2029fLSPXvOrvziC73m\nGv2v/1JVPXFCf/MbveoqbdNG+/fXDz907nPu2Wj6+an3+GnKsRQXq4i2bet80DbeVUNnfscOHTNG\nO3bUoCAdN07//e/6ZwP/QUC7zyefOB/3PXvqww/rqlXOlHRYvVp9fDQkRCdM0O7dVUSTklRVN2xQ\nEb3++vrL5/rsM73mmrOJWc+WLSqi11yjf/jD2RHisGEqotu36+rVKqIdOmh8vHOgPXmyqurbbztj\nPSZG+/ZVEfX21jZt9IYb1N9fRXTRosaad8nxV2HePNdb7XZ9+WUV0Xbt9N139eRJ/eAD53A7IEBF\n9PvvGyzn2LNNG/35z3XMGOfZdhxpRoZ26aIiet11+vOfq83muslvv1UR9fHR8vKzK//rv1REn3rK\n9Vk6t+GGTmZdDz2kIjp1quuTkJOjUVEqor/4hV53nYqol5fu3n32GOuejaafn7qPnyYey7ZtKqKx\nsU3qyuWZ//RT9fLSwECNj9foaOddgAYQ0O5TU6Nz52qbNmdHKP7++uCDWlOjJ09qp04aEKB792pB\ngfOJFB6uqvrUUyqi8+fXXz7XmjUqoocPu976+9+riP7mN3r4sPMpV1mprVuriB4/rr/7nd54o/PJ\n5ph/cMxLzJqlIjp+vNrtmp7ubNsxRfPrX6uIPvdcY8275BijbdzovPi3v2nfvs7/pk1T/c/fklGj\nnDs4pgJ69NAvvtCSEj1xosFyjj3799fKSlXVESNURP/0J1XVW245O01RVKStWv1oHqPWe++5GFmP\nHKkiunp1g2epXsMN7VZXTIzzNl26/XYV0QULnBevvdb5F+Lcs2G3N+P81H38NPFYnnlGRXTu3CZ1\n5fLMT5umInr33VpVpUeO6K236syZro8aBLT7nTmjO3fqCy/o8OHOvNux4+wMbN3/HDExYYLKf144\nqrtc1w8/6OHDzlcgP/9cDx/Wo0fr7+N4dejdd1VVr7lGRXTdOuf0haoWFenSpfqrX2mfPs7qL7+s\nqjp0qIrotm2qqp9+qiJ69dXOG4yNVRHdsqWx5s9ltztfdjtwwLnm7rvPXssx0HOEwqOPOndwTAr/\nz/84LzZSzrFn7ctZjuY/+0wPHlQR7d5dq6qcmxxTsf/6V/32Hn5YRfTee8+uKSlRPz+12fTQoQbP\nUr2GG9qtLsff6b17XZwix0RE585aUfGjrp5/3sXZaNb5qfv4aeKxOB4277/fpK7OPfP6n78KIhoS\noomJP5rSwTkIaDfZtUt/9ztdufLsGrvdGRNpaTp3roroPffotm1n//v6a1XVsDAV0R9+qL9cV1BQ\n/Sfkuf+KdNRyzDO++qqKOJ+Z06bpgQPapYv6+eltt+nixRoR4RwmV1Sor6/abM4ZTMfcyMMPq6pW\nVzvfdVBU1FjzLoWEuPgzc999KqJvvqmqmpBwNnFqJ4Xz8px7NlSuds9jx1TV2byXl5aW6kcfqYhO\nmOC8haIi9fJSX9+zWVPLMVh+/fWzaxzn6rbbGjxL9RpuZLe6d72fn8qP30Py/ffav79ed51zDFt3\nImv0aBXRDRtcnI2mnx+t8/hp4rGoOmdIDh1y/nluvKtzz7yqVlfrX/+q/fuffXCuX+/iUQFVJaDd\nxvF+iW7dND1d7XatqdEPPlCbTTt00PJynTNHRfTWW1VV7XZduVJfeUWPHNHcXBXRTp3Ubv/Rcj3r\n1+uaNfrf/60iunSprlmjn3/+ox0cw5+AAOdLPceOOf+N7xgBTZyoIvqXv6iqbt+uIurjo2fO6O7d\nKqI//7nzRmoHU6q6f7+KaHS0qjbYfENuuklFtGdPTU9XVS0r00WLnM04hleOKdGMDFV1zqtERJy9\nekPlHHtGRjp3++orFdGrrlJVXbFCRbRXL7Xb1W7X++9XER06tH5jtX91HLlZU6NbtjiHz/v2NXiW\n6jXcyG51DRyoIpqQoKdPq6pmZTn/Nsyd63wx+ec/15oa553rOF3l5S7ORtPPT93HTxOP5ehRFdEO\nHdRuP39XLs/8G2/onXfqhg2qqt9+65yDdvwZhisEtJvk5mrHjs4Y6tjROeLw8tLkZNX/TPyJ6IgR\n2q+fiujEiVpT45yFuOkmVf3RskuNzEE7JiIdL/U4jBvnrLhjh159tXNAPWWKM6EGD1ZVff11FdE7\n73RepVs3FdHMTFXVv/xF5cezluc235Bvvjn7HvDQUPX11VattE8fbd1aKyu1rMy5adYsra7Wd95x\nDmBrNVSu3p6Oke8996iq/vvf6uWlIjpggA4e7Lz6/ffXb+x//9e5qVcv7dv37L9LHP+Kb+gs1Wu4\nod3qceSdiLZurV27Ol+0vO46PX1ajxxxvtx3xRV6/fXaqpUGBOiOHarq4mw0/fzUffw08ViSk1VE\nb7xRVZvRVd0z75gwadNGb7pJr79ebTYNCdGcnAYfG5c9PknoJl27SkqKJCRI165y6pSEhsr06bJv\nn0yYICJyww2yfLn06iVffy2VlfLCC/Lhh+LlJWlpIiJDhojIj5aby3HdwYPPrrn9dufCoEHyzDPS\ns6dkZ8vJk/L44yIiWVmiKrt3i4gMHSoicuSI5OZKSIhERorIjzY11HxD+vWTr7+WCRMkLEwqKuTa\nayUlReLiZOBA8fERf3+Jjxd/f0lJkVatnIV+8YuzV2+oXL09v/rqbIfR0fLmm9Ktm+TkyFVXyc03\nuz6TjrMkIv/+t/zv/4rNJnFxsnatzJsnIg2epXoNN7RbPZMny/r1cs010rq1nDkjQ4bI66/L5s3i\n7y9hYbJhgwwfLseOyaFDMnWq7N0ro0adPe11z0bTz0/dx08Tj6Xuvdz0ruqe+UcflfnzJSREPv1U\n0tNl2jT57DPp1q2BRwbEpuc+VgAABmAEDQCGIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOAoQho\nADAUAQ0AhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgAYA\nQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCGIqABwFAENAAYytKAttvtJ0+etNvtVhYFAA9lRUCXl5cv\nWLCgV69efn5+QUFBvr6+0dHRCxcurKiosKA6AHgoKwJ6xowZqampy5Yty8vLq6yszM/PX7Fixb59\n+2bNmmVBdQDwUDZVbeka7du3T09PDwsLq7vy9OnTERERBQUFLV0dADyUFSPoyMjIzZs311u5ZcuW\n8PBwC6oDgIeyYgSdlpYWHx8fHBwcExMTGBhYWlqanp5eVFSUnJw8ePDglq4OAB7KioAWkerq6pSU\nlMzMzOLi4uDg4CuuuCIuLs7b29uC0gDgoSwK6HPl5ubu2bNn/PjxbqkOAOZz2xg2NTU1MTHx1KlT\nDe3w1Vdf/f3vf6+3sqSkJDY29qabbmrh7gA3+PTTT9PS0pp1leuuu27YsGEt1A/czm0j6PPKzc1N\nT0+vt3Lnzp1BQUFz5851S0tAi7rjjjtuWbkypMn7HxT57pFHlixZ0oI9wa3cM4KuqKjw8/NrfJ9u\n3bp169at3srjx48XFha2WF+Am10r0r3JO3cQ+a4Fe4H7WfE2u4KCggceeGDkyJGPPfbYsWPHBgwY\n0Lp166FDh373HY8uAGiQFQF97733ZmZmzp49+/jx4wMHDvzlL395/PjxG2+8cc6cORZUBwAPZcUU\nx6effpqbmxsUFDR27Ni33norKSkpODj4t7/97bkzGACAWlaMoDt27Hjw4EER6dChw/vvv9+hQwcR\nyc3Nbdu2rQXVAcBDWRHQCxcuHDt27KRJk+x2+7Rp00TknXfeiY+Pv/feey2oDgAeyoopjrvuumvk\nyJFffvmlzWZzrKmsrHz++ecnTpxoQXUA8FAWvc2uZ8+ePXv2rL3I2BkAzoufvAIAQxHQAGAoAhoA\nDEVAA4ChCGgAMBQBDQCGIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOAoQhoADAUAQ0AhiKgAcBQ\nBDQAGIqABgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADEVA\nA4ChCGgAMBQBDQCGIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOAodwQ0AUFBSUlJdbXBQDPYkVA\nT5gwITs7W0RycnKGDx8eGhrauXPn0aNHHzlyxILqAOChrAjobdu2lZWVicjcuXP79OlTWlpaVlY2\ndOjQ2bNnW1AdADyUt5XF0tLSNm7c2KZNGxGZP39+RESEldUBwLNYNAd99OjR6urqvn37Hjp0yLFm\n//79AQEB1lQHAE9kxQg6NjY2MTHx2LFj/v7+Bw8evPnmm1NSUiZPnvzkk09aUB0APJQVAb1161YR\nqaqqysrKysvLExF/f/81a9bExcVZUB0APJR1b7Pz8fGJioq65pprROTqq6+Ojo5ev369ZdUBwONY\n+iJhXampqYmJiadOnWpohw8++ODNN9+st/LYsWNjx45t4dYAwAhuC+iEhISEhIRGdpg6derUqVPr\nrVy9enVhYWFL9gUAprBuiqO4uFhVay/W1NQQtQDQCCsCOj09PSYmpmPHjj179qydd87Ozu7UqZMF\n1QHAQ1kR0DNnzpwyZUp5efnbb789c+bMtLQ0C4oCgKezIqB37949b948X1/f2NjY1157bebMmTU1\nNRbUBQCPZkVAh4eH79y507EcHx8fHh7OR1QA4LysCOjnnntu+vTpI0eOzM/Pt9lsy5Yt27Rp0+TJ\nky0oDQCey4q32U2aNOngwYO7du3y9/cXkZCQkNTU1LVr13799dcWVAcAD2XR+6BDQ0MnTZpUe9HP\nz2/atGnTpk2zpjoAeCJ+8goADEVAA4ChCGgAMBQBDQCGIqABwFAENAAYioAGAEMR0ABgKAIaAAxF\nQAOAoQhoADAUAQ0AhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0\nABiKgAYAQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCGIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOA\noQhoADAUAQ0AhrI0oO12+8mTJ+12u5VFAcBDWRHQ5eXlCxYs6NWrl5+fX1BQkK+vb3R09MKFCysq\nKiyoDgAeyoqAnjFjRmpq6rJly/Ly8iorK/Pz81esWLFv375Zs2ZZUB0APJS3BTWSk5PT09PDwsIc\nFzt06DBixIiVK1dGRERYUB0APJQVI+jIyMjNmzfXW7lly5bw8HALqgOAh7JiBL18+fL4+PjFixfH\nxMQEBgaWlpamp6cXFRUlJydbUB0APJQVAT1kyJCsrKyUlJTMzMzi4uLg4OCkpKS4uDhvbyuqA4CH\nsigivb29x44dW3dNbm7unj17xo8f39BV8vPz9+3bV2/l/v37g4ODW6RFmOTAgQN5eXlN399ms40Y\nMcLf37/lWgKs57YxbGpqamJi4qlTpxraISMjY/v27fVWfvvttzExMS3cGtzvzjvvvP7rr5u+/9ci\n93344a233tpyLQHWc1tAJyQkJCQkNLJDbGxsbGxsvZWrV68uLCxsyb5ghHbt2j3bnP1fE+EDULj0\nWPdJwuLiYlWtvVhTU0PUAkAjrAjo9PT0mJiYjh079uzZc/369Y6V2dnZnTp1sqA6AHgoKwJ65syZ\nU6ZMKS8vf/vtt2fOnJmWlmZBUQDwdFYE9O7du+fNm+fr6xsbG/vaa6/NnDmzpqbGgroA4NGsCOjw\n8PCdO3c6luPj48PDw5988kkL6gKAR7MioJ977rnp06ePHDkyPz/fZrMtW7Zs06ZNkydPtqA0AHgu\nK95mN2nSpIMHD+7atcvxOYKQkJDU1NS1a9d+3Zw3ugLA5cai90GHhoZOmjSp9qKfn9+0adOmTZtm\nTXUA8ET85BUAGIqABgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAo\nAhoADEVAA4ChCGgAMBQBDQCGchHQDz744M6dO/nZQABwLxcBHRwcPGfOnG7dus2aNWvHjh3V1dXW\ntwUAcBHQTz311DfffPPll1/27Nlz4cKF3bt3nzFjxtatW6uqqqzvDwAuWw3OQXfo0CE8PDwqKqqy\nsvLLL79cuHBhZGTkmjVrrGwOAC5nLgL6hRdeiIuL6969+/LlywcNGvSvf/3rwIEDX3755XvvvTdr\n1izrWwSAy5OLH41NT09/8MEHr7/++sDAwLrrhw4d+vrrr1vVGABc7lyMoN944428vLx//vOfIrJ2\n7drFixdXVFSISNu2bSdPnmx1gwBwuXIR0ElJSW+99Vb79u1FpEePHuvWrbv//vstbwwALncuAvrj\njz/+4IMPhgwZIiL9+/d/7733Pv74Y8sbA4DLnYuA7tKlS0FBQe3FI0eOdOzY0cKWAAAiLl8kXLRo\n0S233HL77bdHRETk5OSsXLly8eLF1ncGAJc5FyPo6dOnf/HFF506dTp48GC7du22b99+5513Wt8Z\nAFzmXIygRaR3795PPPGExa0AAOpyEdCffvrpE088cfz48borMzIyrGoJACDiMqDvvvvuX/7yl7/+\n9a+9vV2PrwEAFnARwVVVVQsWLPD397e+GwBALRcvEj7yyCMvv/wy3zIKAO7lYgS9du3avXv3PvPM\nM2FhYTabzbGSOWgAsJiLgF6+fLn1fQAA6nER0H369BGRmpqagoKCLl261A6iAQBWcjEHfeTIkbFj\nxwYFBV155ZU//PDDsGHDMjMzL2LJgoKCkpKSi3iDAHBJchHQd911V58+fQoLC4OCgn72s5/deOON\nSUlJF1JjwoQJ2dnZIpKTkzN8+PDQ0NDOnTuPHj36yJEjF3KzAHBpcxHQn3/++aJFi1q3bi0iXl5e\nDz300K5duy6kxrZt28rKykRk7ty5ffr0KS0tLSsrGzp06OzZsy/kZgHg0uZiDjo6Ovof//jH+PHj\nHRf37NnTo0ePi1IsLS1t48aNbdq0EZH58+dHRERclJsFgEuSixH0n/70p8TExISEhOPHjycmJk6b\nNu3Cv83u6NGj1dXVffv2PXTokGPN/v37AwICLvBmAeAS5mIEfd1113377bfr168fMGBAaGjoH/7w\nh7CwsAupERsbm5iYeOzYMX9//4MHD958880pKSmTJ09+8sknL+RmAeDS5vrbNjp27HgRv2J069at\nIlJVVZWVlZWXlyci/v7+a9asiYuLu1glAODS4yKghw0bdu7KC3ydUER8fHyioqKioqJE5Oqrr87N\nzV2/fn3tTDcAoB4XAf3HP/7RsaCqOTk5r7322gMPPHDRC6empiYmJp46daqhHbZs2XLubyFmZmYO\nHjz4ojcDAAY6/wh6zJgxo0ePnjp16sUtnJCQkJCQ0MgOw4cPj46Orrdyw4YNNTU1F7cTADDT+b/x\nOTs7++J+krCJ2rVr165du3oru3TpUlhYaH0zAGC984ygq6urv/nmGz5RAgDWa2wO2qF9+/a9e/e+\nkBqNfFWp44uZAADnauq7OC7EI488smnTpjZt2gQHB9fblJOTc3FrAcAlw0VAd+/evaysTFVdXuEn\nfBHdxo0bk5KS/Pz8Xn311WY3CACXKxcf9X7iiScGDBiwYcOG9PT0zZs3Dx069Kmnnvr+P35amenT\np0dGRl5IowBwuXExgl60aNGuXbu6desmImFhYStXrhwyZMhvfvObCykzZsyYMWPGXMgtAMDlxsUI\n2maz1X1f3aFDh+x2u4UtAQBEXI6gH3/88UmTJs2YMSMqKiozM3Pp0qW//e1vre8MAC5zLkbQM2bM\n2LRpU2Vl5fbt20tLS1etWjVv3jzrOwOAy5zrTxL+4he/GDx4MD8aCwBu5IYfjQUANIUVPxoLAPgJ\nrPjRWADAT+AioB0/Glt78SL+aCwAoOlcvEj4pz/96dZbb42Li3P8aOyGDRveffdd6zsDgMucFT8a\nCwD4CVwEdL9+/d55552L+KOxAICfwMUc9G233fbnP/+5srLS+m4AALVcjKC3b9++d+/ev/3tb6Gh\noa1atXKsbORL9wEALcFFQL/xxhvW9wEAqOdHAR0QEJCTk+P4Gaq//e1v8fHxAQEBbmoMAC53P5qD\nLisrq12eNWsWv58NAG7k4kVCAIAJCGgAMFT9Fwn37NkTGBgoItXV1fv27aud5RgyZIjVrQHA5e1H\nAd2xY8epU6c6llu3bn333XfXbmI+GgAs9qOAJoUBwBzMQQOAoQhoADAUAQ0AhiKgAcBQBDQAGIqA\nBgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADGVpQNvt9pMn\nT9rtdiuLAoCHsiKgy8vLFyxY0KtXLz8/v6CgIF9f3+jo6IULF1ZUVFhQHQA8lBUBPWPGjNTU1GXL\nluXl5VVWVubn569YsWLfvn2zZs2yoDoAeKj6v+rdEpKTk9PT08PCwhwXO3ToMGLEiJUrV0ZERFhQ\nHQA8lBUj6MjIyM2bN9dbuWXLlvDwcAuqA4CHsmIEvXz58vj4+MWLF8fExAQGBpaWlqanpxcVFSUn\nJ1tQHQA8lBUBPWTIkKysrJSUlMzMzOLi4uDg4KSkpLi4OG9vK6oDgIeyKCK9vb3Hjh1bd01ubu6e\nPXvGjx9vTQMA4HHcNoZNTU1NTEw8depUQzt8+OGHzz77bL2VxcXFU6ZMaWKJESNGVKamNr2lApHl\nW7def/31Tb9Kcz377LMr5s9v2+T9K0SOi4Q1p8RRkW8KCkJCQprdXJNNmjQpZ926ZrXkLdKpOSX+\n3cyWdot8ftttzzXnKl1uvnnDhg3NrGOWH0RWvfjiZy++2PSr5ItkqbZcS9L85933IkEiwc0p0dz7\nrrnPu2qRq2fMWLp0aXOaahFuC+iEhISEhITm7rB69erCwsImlvDz8/uyOS29JlJSUtKcazTbiRMn\n3hYZ1uT9/0/kKZFVzSlxh0h5eXmzO2uOEydOpDVn//8n0knk4eZcpVlPVxE5I/KsyNTmXGXU6dPN\nLGKcMyLTRJY05yqjWqqXs5r7vJsmktDC911zn3f5InNaOAqaiI96A4ChCGgAMJQVUxwZGRkNberT\np48FDQCAJ7IioB955JFNmza1adMmOLj+1GJOTo4FDQCAJ7IioDdu3JiUlOTn5/fqq69aUA4ALg0W\nzUFPnz49MjLSmloAcGmw6G12Y8aMGTNmjDW1AODSwLs4AMBQBDQAGIqABgBDEdAAYCgCGgAMRUAD\ngKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCGIqABwFAENAAY\nioAGAEMR0ABgKAIaAAxFQAOAoQhoADAUAQ0AhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAMRUADgKEI\naAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADOWGgC4oKCgpKbG+LgB4FisCesKECdnZ2SKS\nk5MzfPjw0NDQzp07jx49+siRIxZUBwAPZUVAb9u2raysTETmzp3bp0+f0tLSsrKyoUOHzp4924Lq\nAOChvK0slpaWtnHjxjZt2ojI/PnzIyIirKwOAJ7Fojnoo0ePVldX9+3b99ChQ441+/fvDwgIsKY6\nAHgiK0bQsbGxiYmJx44d8/f3P3jw4M0339OMvIEAAA6ASURBVJySkjJ58uQnn3zSguoA4KGsCOit\nW7eKSFVVVVZWVl5enoj4+/uvWbMmLi7OguoA4KGsm4P28fGJioqKiooSkauvvjo3N3f9+vXjx49v\naP/vvvtuz5499Vbu2rWrU6dOLdsoAJjB0hcJ60pNTU1MTDx16lRDO5SWlhYXF9dbeerUqaCgoBZu\nDQCM4LaATkhISEhIaGSHgQMHDhw4sN7K9u3bFxYWtmRfAGAKSz9JaLfbT548abfbrSwKAB7KioAu\nLy9fsGBBr169/Pz8goKCfH19o6OjFy5cWFFRYUF1APBQVgT0jBkzUlNTly1blpeXV1lZmZ+fv2LF\nin379s2aNcuC6gDgoayYg05OTk5PTw8LC3Nc7NChw4gRI1auXMknCQGgEVaMoCMjIzdv3lxv5ZYt\nW8LDwy2oDgAeyooR9PLly+Pj4xcvXhwTExMYGFhaWpqenl5UVJScnGxBdQDwUFYE9JAhQ7KyslJS\nUjIzM4uLi4ODg5OSkuLi4ry93fYmPwAwn0UR6e3tPXbsWGtqAcClgZ+8AgBDEdAAYCgCGgAMRUAD\ngKEIaAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCGIqABwFAENAAY\nioAGAEMR0ABgKAIaAAxFQAOAoQhoADAUAQ0AhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAMRUADgKEI\naAAwFAENAIYioAHAUAQ0ABiKgAYAQxHQAGAoAhoADGVpQNvt9pMnT9rtdiuLAoCHsiKgy8vLFyxY\n0KtXLz8/v6CgIF9f3+jo6IULF1ZUVFhQHQA8lBUBPWPGjNTU1GXLluXl5VVWVubn569YsWLfvn2z\nZs2yoDoAeChvC2okJyenp6eHhYU5Lnbo0GHEiBErV66MiIiwoDoAeCgrRtCRkZGbN2+ut3LLli3h\n4eEWVAcAD2XFCHr58uXx8fGLFy+OiYkJDAwsLS1NT08vKipKTk62oDoAeCgrAnrIkCFZWVkpKSmZ\nmZnFxcXBwcFJSUlxcXHe3lZUBwAPZVFEent7jx07tu6a3NzcPXv2jB8/3poGAMDjuG0Mm5qampiY\neOrUqYZ2+Oijj9544416KwsKCsaNG9fEEiUlJdc3p6V/iwT//vdvvvlm069y7NixLl26NH3/zMzM\nT0WCmrz/aZFMkWYdxW6RrF/9ytfXt4n7V1VVFRcXd+7cuekl0tPTm9XSIREfkY3NuUp5M4/6gEi6\nSDPuOcdRXN+MIgUFBY43iTZxf1U9duxYaGho00tkZGTcLuLX5P2PiZwQ2df0AiK7RZp11GVlZZWV\nlcHBwU2/yoEDB0y775r7vKsUCffxaU5HLcWmqu7uAQDgAp8kBABD8UlCADAUnyQEAENZMQfdvn37\nup8kdDh9+nRERERBQUFLVwcAD8UnCQHAUFaMoNPS0uLj44ODg8/9JOHgwYNbujoAeCiL3mZXXV1d\n95OEV1xxBZ8kBIDG8T5oADAUP3kFAIYioAHAUAQ0ABjqUn6ZbtCgQV5env0XyG635+fnN+sLdwxU\nVlZWVVXVvn17dzdyQQoLCwMDA/38mv5dRibKzc3t1q2bu7u4UP7+/p9//rm7u7DCpRzQQUFBf//7\n393dxQXJz8+fM2fOqlWr3N3IBVm3bl1mZubDDz/s7kYuyPz58ydOnDhs2DB3N3JBRo0a5elPChEZ\nNWqUu1uwiGcPMAHgEkZAA4ChCGgAMBQBDQCGIqABwFCXckD7mPGrYhfCy8vL098pKCKtWrVq1aqV\nu7u4UF5eXpfAUVwCTwq5VI6iKS7l7+KoqKjw9HetyiVxFHa7vaamxtOfVJWVlT4+Pjabzd2NXJBL\n4OEkl8pRNMWlHNAA4NE8/p/PAHCpIqABwFAENAAYioAGAEMR0ABgKAIaAAxFQAOAoS6pgP7Xv/41\naNCg4ODgxMTEioqKelvXrVvXp0+ftm3bjho1Kj093S0dNq7x/hvfag5Pvxekaac6IyMjICDA4saa\npfGjOHLkyLhx49q1azds2LBvv/3WLR02ReNHsXTp0sjIyDZt2sTFxWVkZLilw5all4qqqqquXbu+\n9dZbubm5Y8eOffLJJ+tuPXr0aGBg4Pr160+cOPH444/HxMS4q8+GNN5/41vN4en3gjbtVFdXVw8f\nPrxVq1bWt9dE5z2KoUOHLl68+OjRow8//HBcXJxbmjyvxo/i4MGDPj4+27dvP3r06AMPPDBq1Ch3\n9dlyLp2A3r59+5VXXulYTklJiY6Orrt1zZo11157rWO5oqLCZrMdP37c6hYb1Xj/jW81h6ffC9q0\nU/3SSy9NnTrV5IBu/Cj27t3bp08fu92uquXl5d98840bWmyCxo/iyJEjgYGBu3btOnny5KOPPnrr\nrbe6o8eWden85NWhQ4euuuoqx3JMTMzhw4ftdnvtNw2NGTNmxIgRjuVdu3ZFRkaa9hN5jfff+FZz\nePq9IE041YcOHXrjjTc2btz48ccfu6nH82v8KPbt29e7d+/77rsvJSXlqquueumll9zXaWMaP4qw\nsLDnnntu2LBhNputQ4cOJk/U/GTGPcN/suLi4sDAQMdyu3btqqurT506Vbs1MDCwc+fOqrpu3brb\nb7/95ZdfNu1bbxrvv/Gt5vD0e0HOdwh2uz0pKWnJkiXt2rVzU4NN0vhRHDt27JNPPhk8ePCGDRu6\ndu06bdo0N7V5Ho0fRUZGxqJFi1JTU8vKyu6999677rrLTW22IM8eQb/yyitPPPGEiLz44ovBwcGl\npaWO9aWlpa1atar3Gk5RUVFSUlJWVtbatWuHDBnihnYb1Xj/5z06Q3j6vSDnO4Tly5d37dr1lltu\nKSwsdFODTdL4UbRu3To2Nva+++4TkRdeeCEgIKCwsDAkJMQ9vTas8aP45JNPbrrpJsfP+D711FNB\nQUEnTpwICgpyT68tw7NH0HPmzCkpKSkpKbn77ruvuOKK2ncFZGRkREZG1v1naUVFxQ033HDllVf+\n85//NDMXGu+/8a3m8PR7Qc53CDt27EhOTg4JCenVq1dNTU1ISMiuXbvc1GljGj+K8PDw2mXHd46b\n+VXXjR9FTU2N3W53LKtqdXW1XnrfzeneKfCLyPGC79q1a0+fPj1lypQFCxY41n/wwQc5OTnvv/9+\n//79D9fhuDvN0Xj/DW01jaffC3q+QygsLMzOzs7Ozv7mm2+8vLyys7PLy8vd2q9rjR/F6dOnO3bs\n+P777584ceKxxx4bOXKkW5ttUONHsW/fvvbt23/22WclJSUPP/xwbGysW5ttEZdOQKvqV1991a9f\nv44dOyYmJtY+bdq2bfvJJ5889thj9f4yFRQUuLfbczXSf0NbDeTp94Ke745wKCgoMPldHHq+o/j8\n88/79esXEBAwbty4H374wa2dNqbxo1i1alWvXr0CAgJuueWWrKwst3baIvjCfgAwlInzmAAAIaAB\nwFgENAAYioAGAEMR0ABgKAIaAAxFQAOAoQhoADAUAQ0AhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAM\nRUADgKEIaAAwFAENAIYioAHAUAQ0ABiKgIYHePfdd0eMGBEQEBAVFfXSSy9drB/S3Lt374ABAxrZ\nwdvbu7q6evPmza1bt74oFYFm8XZ3A8B5vPjii3/84x9ff/31gQMH7t+//5577gkMDLz33nsta6Bf\nv35/+ctfLCsH1GIEDaOVlJQ8/fTTa9asGT9+fLdu3caNG7dkyZJVq1Y5tn700Ue9e/cOCgqaMmVK\nfn6+iGRkZMTFxS1atKhfv351l0Vk586dAwYMaNu27bhx444ePVqv0J///Ofu3bv7+/sPHz784MGD\nInLDDTfU1NRERUUdPXr06aefbqTitddeu3jx4m7duvXo0WPHjh2WnRxc8ghoGG337t1du3YdPHhw\n7Zrp06dv27ZNRDIzM++5557XXnvt8OHDQUFBc+bMceywd+/erKysFStW1F0uKiqaPHny008/nZOT\nExUVdccdd9Stkp+f/9BDD7333nvZ2dm9e/desmSJiGzdurVVq1aHDh1q27atY7dGKlZVVR08ePC2\n2257/PHHW/6s4HLBFAeMlpWVFR4e7nJTcnLypEmTxo4dKyLPP/98165da2pqRKSmpubVV1/19fXN\nyMioXV6xYsWoUaPi4+NFZMmSJSEhIXa7vfamAgMDMzIyevToUVFR0bVr18zMzGZV9PLymjdvnre3\n9x133LFu3bqLfQ5w+SKgYbTQ0NC8vLy6a86cObNq1arp06fn5eVFRkY6Vnbq1MnX17egoMBxFV9f\n39qrO5azs7O3bt1au7+Pj49jgsLBz8/v/fffT05ObtWqlZ+fX6dOnVw201DFsLAwb29vEXH8H7hY\nmOKA0QYPHvzdd98dOHCgds327dvnz5/v5+cXGhr6ww8/OFYWFRVVVlaGhISISKtWrWp3rl0ODQ2d\nMmXK999///3332dmZu7Zs6dLly61u3344YcfffTRunXr/vGPfyQmJjbUTEMVbTbbxTpeoC4CGkYL\nDQ196KGH4uPj169fn5ubu2PHjoceemj27Nk2m23ChAlr1qzZsWNHcXHxo48+Gh8f38gA9uabb96w\nYUNKSorjVcfp06fXTdW8vDxfX1+bzZaamvryyy8fP37cMXchIqWlpbW7NasicBEoYDa73f7KK68M\nGjTI39//iiuu+P3vf19VVeXYtHr16ujo6MDAwIkTJ+bl5alqenp67969HVvrLqvqxo0br7zySn9/\n/1GjRn333XequmfPnv79+6vq8ePHR48e7e/vP2zYsI0bN0ZERLz77ruqOn369MDAwLS0tNrbaVZF\n4ALZ9CK95x8AcHExxQEAhiKgAcBQBDQAGIqABgBDEdAAYCgCGgAMRUADgKEIaAAwFAENAIYioAHA\nUAQ0ABiKgAYAQxHQAGAoAhoADEVAA4ChCGgAMBQBDQCGIqABwFD/H08KshbNHKaZAAAAAElFTkSu\nQmCC\n",
       "prompt_number": 8,
       "text": [
        "<IPython.core.display.Image at 0x103533650>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 6"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot6.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxN+eM/8Pdt3xdZ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\nAElFTkSuQmCC\n",
       "prompt_number": 9,
       "text": [
        "<IPython.core.display.Image at 0x103533850>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Graph 7"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot7.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1yUdd7/8c/ISRBE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\n1P8Hc6SoenSBI10AAAAASUVORK5CYII=\n",
       "prompt_number": 10,
       "text": [
        "<IPython.core.display.Image at 0x103533950>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 8\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot8.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxNeeMH8O+tdFtc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\n",
       "prompt_number": 11,
       "text": [
        "<IPython.core.display.Image at 0x103533990>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Graph 9"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot9.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVyU5f7/8c+wj2zJ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\nQmCC\n",
       "prompt_number": 13,
       "text": [
        "<IPython.core.display.Image at 0x1035339d0>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot10.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3dd1xTV+MG8BMS2UNc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\n",
       "prompt_number": 12,
       "text": [
        "<IPython.core.display.Image at 0x103533910>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 11"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot11.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxU9f7H8c+wyiYC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\n",
       "prompt_number": 14,
       "text": [
        "<IPython.core.display.Image at 0x103533a10>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 12"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot12.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3dd1gU58I28FlYdmkL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\nAAAAAElFTkSuQmCC\n",
       "prompt_number": 15,
       "text": [
        "<IPython.core.display.Image at 0x103533a50>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 13"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot13.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxU9f4/8M/AMKzD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\nAFAKAQ0AQCkENAAApf4/XekZ2HPUFSIAAAAASUVORK5CYII=\n",
       "prompt_number": 16,
       "text": [
        "<IPython.core.display.Image at 0x103533b50>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 14"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot14.png')\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVwUdeMH8O8enMty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\nAABJRU5ErkJggg==\n",
       "prompt_number": 17,
       "text": [
        "<IPython.core.display.Image at 0x103533a90>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 15"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot15.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVyU5f7/8WtgZBFG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\ngKQIaACQ1P8DfNiX/VzJBbAAAAAASUVORK5CYII=\n",
       "prompt_number": 18,
       "text": [
        "<IPython.core.display.Image at 0x103533bd0>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 16"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot16.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxM6+MH8DPT1LRq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\n",
       "prompt_number": 19,
       "text": [
        "<IPython.core.display.Image at 0x103533b90>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 17"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot17.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVzVVf748fcFZBEu\ni0CAgCiIQKG49tMWRDMzUxLTpL4tLknlUjRTYxvjkq0u2Zi0WDqOWqm5azoOGSnjvoE4YCKpgCI7\ngijr/f1xZxgGr6gXvBzk9Xz06HH53Hvued8bvbh82DQ6nU4AAOoxa+4BAACGEWgAUBSBBgBFEWgA\nUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSB\nBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEegWIK8077VVr/m/428zycb7T94RsRGHzhyq\ne4O0nLSH5z9sN8UuZGbIrt921b3K/Y/umoma2n98pvlM/X7qpSuXrt1l5uaZdW+pmagpLS8VkXMF\n54YtHKadonV61enZb58tLCvU3/56x2ttT96umagZtnDYzTyEa12tvKqZqLF40aLe5VtVVVOlfzjv\nb32/9uAz3zyjmah5d8O7Rtzhzaj72OspLCucvHJytxndbCfbBsUETVs7reBywW0aQ4x96vTPWFVN\n1W2aCjeJQKuusrpy2F+GLYhbcCbvTJBHUGV15YajG0I/CT2edbz2NqO+HBWXEjcwcGBaTtqoL0dd\n+/9VR+eO97S/p5NLp3MF5z7f+fmU76dcu1FaTpqVhVWId0jtP2YaM51ON3zh8K1JW7t6de3QrsOK\nfSvGLR0nItc7bvRDMIGPtn108dJFU+54rbP5Z7vN6BYbH3s867jWWnsq59Qn2z8J/SRU/7GwGfWe\n3VszUbMvfV/zjoF6CLTqjpw7sv/3/T7OPrmf5h6JOZI5J/O5fs9dqbzy9a6v9TfIK81LzEjsfFfn\nTVM2RfSIyC3JzbmUU+9Olo5bmjwzOf3D9JUvrBSRVQdXXRvxUxdP9fPrd+zPx2r/aWvZNjEzMSkz\nqZdPr4RpCfvf3n+X9q7NiZsLLhdc73jdO+zq1VVEenj3uOFDMI3S8tIZm2aYZq/ax17v+Fvr3sos\nzOzRoceZj85kz8s++/HZII+gE+dPLIhbYJrBblLJ5yUln5eYa8ybe5DWjkCr7nzReRFpa9m2rWVb\nEbEws5g+fPrCpxYOvnuw/gaObR2d7ZzTctKW7VkWfzLew8HDw8Hjevc26O5BIlJRVXHtp9VpuWkd\n2nWodzD+ZLyI9O/S30xjZt3Guq9v3xpdTUJawvWO113r6ej59P97elSvUTd8COm56eGfh7u85uL5\nhudzS57LLck18slqkIeDx+Ldi1MupNQ7HpcS1+/DfvpzNQ/Ne+jw2cMikpaTppmo8Xvb79N/fOr1\nhpfPNJ/Pfv5sX/q+nu/1tJtiFzYnLD03vYHhax973Y3yS/O/P/C9iCx+brGPs4/+ZnNHz72/8/35\npfkiUnK1JPqHaP93/G0n23af1f2b3d/odDoRyS7O1kzUuLzmsvf03t6ze/94+Mdrj9zk02jwwfae\n3Vt/od+H/X44+MPVyqvaKVrHVxw1Gs3NTLX+6Prg6cHaKdrhC4c3++codxgCrbpePr2sLKxSLqR4\nvO4xbum4bxO+vVJ5ZfKAycNDhutvYGFmMWfUHBEZu3RsweWC5ROW6/+/MuiX1F9ExM7KztXOte7x\nwrLC/NL8k9kn/d/xt59qP2TBkN8u/iYieaV5IuJs56y/mf5Cbknu9Y7X227lCytDvEMafgglV0vu\n++i+n47/1M+3n6+L7/K9ywfOG3irZz+/3vX1Y395rOHbzHp8VnVN9Z9+/FPdgxkFGeELww+eOdi7\nY2//u/x3pu6MiI3QB0hE0nPT31z3pp213bmCc9E/RPef019/+v7X3359fc3rDQ+vf+x19zqVc0pE\nXLWuvXx61R4c2nVowrSET8d8qtPpwj8P/+znz8qrygcEDvgt+7eJf5s4/x/za295tfLqmK/H6Et6\n7ZGbeRqv92BnPT6ro3NHEZk+fHpf3751l9xwqqKyoueXPG9lYVVWUbYlacvtO63fOhFo1XVo12HT\nlE1dPbsWXC74656/vrDsheDpwQHvBvwz7Z/6G1TVVNW+mru/8/0DAgccPnt4QdyCnJL/nuh4YdkL\n3Wd1D3g34KnFT4nIi/1frBfxtJw0ETl09lCAe4Cvq+/fT/x98KeDyyrKSq6WiIiVhZX+ZvqXwKXl\npdc7bsRDWPLPJRcvXXz+vueXjlu6fvL63h17J2clb0ncckvP0rmCc/t/39/wbcICwsJDwrckbdmZ\nurP2YHpeemiX0OnDp//y+i8J0xKs21hnFGToP/zoJU5PTH0vNbRLqIg80fOJU++f2jxls4gkZSbd\n6vBZRVkicpf2LoPX/vrbr/En473beZ+YeWLL1C3bo7eLyHtb3qvR1ehvcLn88qSwSXmf5tV+bK57\n5GYmud6DHdp1qP5D7JDgIfpS3/xU1TXVu/+0+3DM4aXjlorI/vQb/FfALTHmy+IwscH3DE66Jymz\nMPPgmYO/pP6y+tDqUzmnxnw1JuOTDBEZvnD49uTtUaFRiRmJcSlxMRtiTueeXnVw1XP9nqu9h9O5\np/UXPBw8xvQZM3vE7HpbuNm7LR23tKNzx7CAsBpdzb3v33v47OGfU362s7ITkauVV/U3019wtnXW\nn+a+9rgRDyE5K1lEliQsWZKwpPb2J86fGBI85IbPTGV1pb56RWVF1TXVZ/LPiIi9tX0723YGb//x\nqI+3Ht/6+prXA90D9Uf6d+nv4eDx4+EfI2Ijjpw9on8g1TXV+ms9HT31t/R28haRgYEDNRqNdztv\nEdG/OL3e8CN6jLh2d09HT/nPJyXX0n/JdHi34VprrYiEdgn1dPTMKsrKLMy0NLcUEes21n8a8icz\nzX9fVNU9cjNPY8MP1ripnNo66T9R6NOxj4iUVZQ1cG+4VQRadfEn4+NS4np26Dmy50gvJ6+IHhEx\nw2Lc/uiWVZSVV5pXfKV4e/L2Xj69vnr2q4uXLvb9oO8HP31gaWHZ17dv3Uj98vovYQFhDezSoV2H\nsfeN1V8205j16NDj8NnDmYWZLnYuUqcp+pMYHg4e+gvXHjfiIZRXlYvI64+8/sg9j9Sd52aenLP5\nZ/3f8a99s9ObnUTkj4P/OHf0XIO3D3QPfDH0xdj42NrPOfae3tt/Tv825m0iekS8PfTtN9e9WVRW\nVHt7C/P/+R+k3psickvD+9/lLyIXL1381/l/3d3+bv3B7cnb31z3ZjevbvrA1WVuZi4iVdVV+hTa\nWtnWrXO9IzczScMP9ibVm8rM7N8DNHBiDUbjFIfqckpy3t/6fvSqaP1LRRFJy0nT6XT2NvbOds42\nljYi8q/z/7pQfMHN3u2TUZ+ISEVVRVRo1C3tErMhRjNRM3nlZBEpqyhLOJUgIgHuAfqs/5zyc1VN\n1aUrl/ac3mNpYdnVq+v1jhvxEILcg0TkauXVQUGDBgUNsm5jnVeap6/ADbk7uK+ftH79pPWjeo2y\ns7LTX679SGPQ9PDpWmtt8ZVi/Zvrjq6rrK6cMnDKihdWDL5n8K0G65aGd7ZzHtNnjIhELY/Sf2zL\nK82buXlmYkaiq51rcPtgEdmStEV/+ighLeFcwTl7G/uOLh2bapIbPthrX003cio0Eq+gVTes27Du\n3t2PZRzzfcs3uH1wXmneuYJzIvLGI2+YaczaO7Tv36X/r7/96v+Of4hXSO152JmbZ47sOdLBxuEm\ndxnVa9TH2z+OjY+NS4krvlJ88dLFfn799N+k0dWz6/Gs40ExQWUVZXmleWPvG3uX9i5XO1eDx414\nCC88+MLH2z+O/SW24HJBTU3NmsNrtNbaf836182MbWdlpz+ZcOjsoV9O/mLwxEI9d2nveuvRt95e\n/7b+TTetm4h89etXKRdS9qfv12g0Op2uWtfQZ/113erwH478MOFUwj/T/un2B7cO7TqcLz5fUVXh\n3c77raFvOds6h3YJ3fXbruDpwd28uulPlE8fPr3eq+bGTNLAg7W1shWR+f+Y79jW0c/Vr3ZJWEBY\nY6ZCI/Esq66tZdu4P8RNGzLN18U35ULK5YrL/fz6/W38394e+raIaDSaNS+tmfDABAcbh6TMpH6+\n/Xa8tiOyT+TZ/LOTVk66+V1CvEO2vbqtn1+/rKIsKwurl/q/tHnKZnMzc41Gs3nq5qFdh14ovlCj\nq4kKjVr0f4v0+xo8bsRDcNW6JkxLeCjooa1JW/9+4u+PdX0sYVpCA98p2HjRD0d7OXnpL78c9vLI\nniMrqyvTctIWRC7o36W/iGxN2nqTd3Wrw3dy6ZQ4PTEqNCrAPSD7UrZPO5/JAyYfePuAi52LRqPZ\nPGXz1IFTLcwtdqbu9Hfz//b5b18b9FoTTtLAg40eFO1m77buyLp6Pz3UyKnQSJra7ygCACiFV9AA\noCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgC\nDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCK\nItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCgCDQCKItAAoCiL5h4AuC3i4+P379/fmHt4\n/PHHAwMDm2oewAgEGnem5cuXL0lfIjbGrs8WrVZLoNG8CDTuXG4iWmPXljflIIBxOAcNAIoi0ACg\nKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAIN\nAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi\n0ACgKAINAIoi0ACgqGYIdHFxcVFRken3BYCWxRSBTklJGThw4KhRo/Lz84cPH+7m5ubi4hIWFpaZ\nmWmC3QGghTJFoF966aW77767U6dOAQEBwcHBxcXFpaWlPXr0mDRpkgl2B4AWSqPT6W73Hm3btv39\n99/btm3r4OBQVlZmbW0tIkVFRR06dLh06dL1Vq1Zs+brr7+ud/DSpUuRkZGvvfba7Z0YChg/fnxG\nRobRy1NSUrIeyBKtseuPSWBpoJeXl3Gra2pqsrKyvL29jd1e7O3t165da/Ry3BksTLCHq6trcnKy\nra2tTqdLSkq69957RSQxMbF9+/YNrBo9evTo0aPrHVy9enVeXt5tnBXKWLp9qTzWiPUHG7f9VUlt\nl5raMdXI5WUip+Vkx5PGD7DV+KW4Y5gi0G+++eajjz5qY2MTGxsbERHx6KOP1tTUrF+/fvHixSbY\nHQBaKFME+uWXX3744YdtbW09PDwGDBiwefPm6urq3bt3BwcHm2B3AGihTBFoEencubP+QmBgYGBg\noGk2BYAWjR9UAQBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBF\nEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgA\nUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFWTT3AAAMKRCNl8b45SWy9+97+/bta9zq\n5OTkrvd1FXvj93/Q98Fdu3YZvx4iQqABRelEHm3E8qNSVlZm9OqysjLpJHKv8fubp5kbvxj/wSkO\nAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAU\ngQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYA\nRRFoAFAUgQYARRFoAFAUgQYARRFoAFBUMwQ6Nze3sLDQ9PsCQMtiikCfPHlywIABSUlJ586d69u3\nr4eHh5ubW2hoaEZGhgl2B4AWysIEezz//PP33XdfQEBAZGTkvffeGx8fr9FoYmJiXnzxxZ9++ul6\nq3JycpKSkuodPH78uJOT022eFwCUYIpAnzhxYuPGjVZWVsnJyXPmzLG2thaRd955x8vLq4FVqamp\ncXFx9Q6ePHkyODj4Ns4KAMowRaD79eu3cuXK1157bcCAATt37uzcubOIbNu2TX/hekJDQ0NDQ+sd\nXL16dV5e3m2cFQCUYYpAL126NCIiYvHixV26dHn55Ze///57nU6XnJy8adMmE+wOAC2UKQLt6el5\n4MCBxMTEpKSkBx980Nra2tvbe/DgwTY2NibYHQBaKFMEWi8kJCQkJMRk2wFAS8cPqgCAogg0ACiK\nQAOAogg0ACiKQAOAogg0ACiKQAOAogg0ACiKQAOAogg0ACiKQAOAogg0ACiKQAOAogg0ACiKQAOA\nogg0ACiKQAOAogg0ACiKQAOAogg0ACjKQKBfeeWVXbt2VVdXm34aAEAtA4F2cnKaOnWqp6fnpEmT\ndu7cWVVVZfqxAAAGAj1z5szExMQ9e/Z07tx5xowZXl5eUVFRO3bsqKysNP18ANBqXfccdLt27by9\nvf38/CoqKvbs2TNjxoyOHTuuX7/elMMBQGtmINBz5swJCwvz8vL65ptvevbsefjw4eTk5D179qxc\nuXLSpEmmHxEAWieLaw+lpKS88sorDz/8sFarrXu8T58+sbGxphoMAFo7A6+gv/zyy+zs7P3794vI\nhg0b5s6dW15eLiK2trYRERGmHhAAWisDgZ44ceK3337r6OgoIp06ddq4cePLL79s8sEAoLUzEOh1\n69atWbOmd+/eIhISErJy5cp169aZfDAAaO0MBNrNzS03N7f2zfPnzzs7O5twJACAiMEvEs6ePfux\nxx57+umnfXx8MjMzV6xYMXfuXNNPhhatpKTkiy++0Ol0zT0IWqS4uLjDhw835h6eeOKJzp07N9U8\nzcVAoCMjI3v06LF69epTp065ubnFxcWFhISYfjK0aGfOnJkWO03ubu450DItXbr0u+zvxMrY9Vni\n6up6ZwZaRAICAmJiYkw8Cu40diKejVh+rMkGQYvkLtLW2LVlTTlIMzIQ6J9//jkmJqagoKDuwdTU\nVFONBAAQMRjo8ePHP/XUU88884yFheHX1wAAEzCQ4MrKyunTp9vY2Jh+GgBALQPfZveHP/zhs88+\n47eMAkDzMvAKesOGDceOHfvggw88PDw0Go3+IOegAcDEDAT6m2++Mf0cAIB6DAQ6MDBQRKqrq3Nz\nc93c3GpfRAMATMnAOejz588PGjTIwcEhKCjo7Nmzffv2TU9PN/1kANDKGQj0uHHjAgMD8/LyHBwc\nOnTo8Mgjj0ycONH0kwFAK2cg0Lt37549e7a1tbWImJmZRUdH79u3z+SDAUBrZyDQ/v7+CQkJtW8e\nPXq0U6dOJhwJACBi8IuEf/nLX5544omwsLCCgoKxY8du3bp1+fLlpp8MAFo5A4Hu37//yZMnt2zZ\n0r17d3d39w8//NDDw8P0kwFAK2f4t204Ozs///zzJh4FAFCXgUD37dv32oN8nRAATMxAoBcsWKC/\noNPpMjMzFy1aNHnyZNNOBQC4iVfQDz300MCBA0ePHm2qkQAAIga/za6ejIwMfpIQAEzvBq+gq6qq\nEhMTp0yZYsKRAAAiDZ+D1nN0dAwICDDVPACAf7vZ7+IAAJiYgUB7eXldvnxZp9MZXFBUVHSbRwIA\niBj8ImFMTEz37t23bt2akpKyffv2Pn36zJw588x/mHxCAGilDLyCnj179r59+zw9PUXEw8NjxYoV\nvXv3fvXVV00+GwC0agZeQWs0mrrfV3f69OmamhoTjgQAEDH4Cvrdd98dMWJEVFSUn59fenr6V199\nNW3aNNNPBgCtnIFX0FFRUdu2bauoqIiLiyspKVm1atUbb7xh+skAoJUz/Nvs7r333l69evFHYwGg\nGfFHYwFAUfzRWABQVPP80dh9+/aVl5c37X0CwB2mef5o7LBhw3Jzc5v2PgHgDmOKPxprZ2d39erV\nukeqq6t9fHw0Gk1VVVVj7hkA7mCm+KOxBw8enDBhgpeX10cffWRvby8iXbp0iY+Pb9++fQOr1qxZ\n8/XXX9c7ePHixUGDBjVmGABoKQwEulu3bn/729+a8I/GBgUF7d69e+HChUOHDp0/f/7QoUPNzMza\ntWvn4uLSwKrRo0df+2dcVq9enZeX11SDAYDKDJyDfvLJJ7/44ouKioom3Mbc3Dw6Onrr1q1z5sx5\n9tlnm/bOAeCOZOAVdFxc3LFjx7777jt3d3dzc3P9wdTU1MZv5ufn9/PPP3/zzTeVlZU2NjaNv0MA\nuIMZCPSXX355+/YzMzOLioqKioq6fVsAwJ3hfwJtZ2eXmZkZGBgoIt999114eLidnV0zDQYArd3/\nnIO+fPly7eVJkybx5TgAaEYGvkgIAFABgQYARdX/IuHRo0e1Wq2IVFVVJSUl1Z7l6N27t6lHA4DW\n7X8C7ezsXPuzIdbW1uPHj6+9ivPRAGBi/xNoKgwA6uAcNAAoikADgKIINAAoikADgKIINAAoikAD\ngKIINAAoikADgKIINAAoikADgKIINAAoikADgKIINAAoikADgKIINAAoikADgKIINAAoikADgKII\nNAAoikADgKIINAAoikADgKIINAAoikADgKIsmnuAO9auXbv6D+0vNsbfw+gBo1evXt10E6E1yZGH\nRj4kbYxdXi7SqSnHMbV8mRA9YcK0CUYur5GoUVFfffVVk85kDAJ9uxQXF0uwSFdj19dIUUZRUw6E\nVqVa5H6R9sYu/02kRb/3VYn0EOli7PIrUlSkxOPnFAcAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4Ci\nCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQA\nKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKIpAA4CiCDQAKMp0\ngS4sLNTpdLVvVldX5+XlmWx3AGhxTBHolJSU4OBgZ2fnzp07b9myRX8wIyPD1dXVBLsDQAtlYYI9\nXnrppZEjRx45cmTfvn1PP/30hg0bevfufcNV+fn5Z86cqXcwPT3d0tLyJvdNS0srLi6+1WlrFRcX\na7VaMzMjP4alpaUZvbVeaWnp4cOHjV5eVFTk6OjYmN0tLS1v/tmup/EPHy1aWVlZY957CwsLxakJ\nx2mpTBHogwcPbtmyxdLSMjQ0dNGiRS+99NL+/ftvuCoxMXHHjh31DqampgYFBd3kvmPGjDlSfeSW\nx611UsRHxNrY5dkiHY3fXGpkb/Le3hNu/JHsupJF7hHRGLv8dxFnEXtjlxeJ2Bm7Fi3fgd8ONOq9\nN0VkVNNN02KZItDe3t67du167LHHRCQ8PPyvf/3rn//854kTJza8auDAgQMHDqx3cPXq1Td/5tre\n3l46GzHvf2SIBIvxH8aNf/XwH/YifRqxPFWkTyMCXSDSRcTb2OVnRC4YuxZ3AJvGvfeebrJBWjRT\nnIP++OOPIyMjH3zwwZycHI1Gs3jx4m3btkVERJhgawBouUzxCnrEiBGnTp3at2+fjY2NiLi4uOzd\nu3fDhg1HjjTi/AMA3OlMEWgRcXd3HzFiRO2bVlZWY8aMGTNmjGl2B4CWiB9UAQBFEWgAUBSBBgBF\nEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgA\nUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSB\nBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBF\nEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgA\nUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFEWgAUBSBBgBFmTTQNTU1ly5dqqmpMeWm\nANBCmSLQV69enT59epcuXaysrBwcHCwtLf39/WfMmFFeXm6C3QGghTJFoKOiovbu3bt48eLs7OyK\nioqcnJxly5YlJSVNmjTJBLsDQAul0el0t3sPR0fHlJQUDw+PugfLysp8fHxyc3Ovt2rt2rVffvll\nvYO5ublDhgz56KOPbmbfHj16HMs9ZsTA/5Yj4iTSxtjlJSIaETtjl+tECkXaGbtcRLJF3EQ0xi7P\nF7EVsTZ2+VWRqyKOxi4Xkcsito1YflHEWcTC2OXFIhaNGKBapLjR//ncG7E8T0QrYmXs8jKRShGH\nRgxQIqJtxPKLIi4i5sYuLxJp06j/fP/30P+tWLHC2PVNxhSB7t69+6uvvjpu3Li6B9evX//ee+8d\nOXLkdu8OAC2UKQJ96NCh8PBwJyen4OBgrVZbUlKSkpKSn5+/adOmXr163e7dAaCFMkWgRaSqqio+\nPj49Pb2wsNDJycnX1zcsLMzCwujPPwHgzmeiQAMAbhU/qAIAiiLQAKAoAg0AiiLQAKAoAg0AiiLQ\nAKAoAg0AiiLQAKAofpZPUTU1NV26dHF0bMxvG2rVLl686OzszE+rGqe8vDw0NHTRokXNPUhrx7uv\noqqrq319fXfs2NHcg7RUEyZMeOedd3x9fZt7kBbpwIEDa9eube4pwCkOAFAVgQYARRFoAFAUgQYA\nRRFoAFAUgVaURqPhW8Qaw8zMzNzc6D9p19qZm5ubmRGH5scv7FdXeXm5lZXRf/WztePZawydTldZ\nWWlpadncg7R2BBoAFMVnMQCgKAINAIoi0ACgKAINAIoi0ACgKAINAIoi0ACgKAKtkMOHD/fs2dPJ\nyWns2LHl5eX1rh08eLD1fwwfPrxZJlRTw89bw9dCeMdTGIFWRVVVVXh4+JQpU06cOJGVlfXBBx/U\nu8HJkye3bdt27NixY8eOxcbGNsuQCmr4ebTSTdQAAAYeSURBVLvhswre8ZSmgxri4uKCgoL0l+Pj\n4/39/eteW1FRYWVlVVlZ2RyjKa3h563ha6HjHU9tvIJWxenTp7t27aq/HBwc/Pvvv9fU1NRee+7c\nORsbm5EjR/r5+T311FOZmZnNNKZyGn7eGr4Wwjue2gi0KgoLC7Varf6yvb19VVVVaWlp7bXZ2dnu\n7u4vvvji1q1bLS0tn3zyyWYaUzkNP28NXwvhHU9t/ELL5rRw4cKYmBgRmT9/vpOTU0lJif54SUmJ\nubm5nZ1d7S3vv//+lJQU/eXY2Fh7e/vc3FxXV1fTz6yahp+3hq+F3Ogp4h2vefEKujlNnTq1qKio\nqKho/Pjxvr6+tf8npKamduzYse4v5N2/f398fLz+sqWlpbm5eZs2bUw/sIIaft4avhZyo6eId7zm\nxTurKsLCwvLz8zdu3HjlypV58+Y988wz+uM//vhjVlbWlStXIiIiEhISiouLY2JiHnjgAUdHx+Yd\nWBENP2/Xuxa1eMdTWnN/lRL/deDAgW7dujk7O48dO/bq1av6g7a2tps3b9bpdPPmzfPw8NBqtY8/\n/nhWVlazTqqWhp83g9eiLt7xlMUv7AcARXGKAwAURaABQFEEGgAURaABQFEEGgAURaABQFEEGgAU\nRaABQFEEGgAURaABQFEEGgAURaABQFEEGgAURaABQFEEGgAURaABQFEEGgAURaABQFEEGgAURaDR\nAixfvvy+++6zs7Pz8/P79NNPm+oPaR47dqx79+4N3MDCwqKqqmr79u3W1tZNsiNwSyyaewDgBubP\nn79gwYLY2NgePXocP358woQJWq32hRdeMNkA3bp1W7Jkicm2A2rxChpKKyoqmjVr1vr164cNG+bp\n6TlkyJB58+atWrVKf+3atWsDAgIcHBxGjhyZk5MjIqmpqWFhYbNnz+7WrVvdyyKya9eu7t2729ra\nDhky5MKFC/U2+uKLL7y8vGxsbPr163fq1CkRGTx4cHV1tZ+f34ULF2bNmtXAjg888MDcuXM9PT07\ndeq0c+dOkz05uOMRaCjt4MGD7du379WrV+2RyMjIf/zjHyKSnp4+YcKERYsW/f777w4ODlOnTtXf\n4NixY+fOnVu2bFndy/n5+REREbNmzcrMzPTz83v22Wfr7pKTkxMdHb1y5cqMjIyAgIB58+aJyI4d\nO8zNzU+fPm1ra6u/WQM7VlZWnjp16sknn3z33Xdv/7OC1oJTHFDauXPnvL29DV61adOmESNGDBo0\nSEQ++eST9u3bV1dXi0h1dfXnn39uaWmZmppae3nZsmUDBgwIDw8XkXnz5rm4uNTU1NTelVarTU1N\n7dSpU3l5efv27dPT029pRzMzszfeeMPCwuLZZ5/duHFjUz8HaL0INJTm7u6enZ1d98iVK1dWrVoV\nGRmZnZ3dsWNH/UFXV1dLS8vc3Fz9EktLy9rl+ssZGRk7duyovX2bNm30Jyj0rKysfvjhh02bNpmb\nm1tZWbm6uhoc5no7enh4WFhYiIj+30BT4RQHlNarV6+0tLTk5OTaI3FxcW+99ZaVlZW7u/vZs2f1\nB/Pz8ysqKlxcXETE3Ny89sa1l93d3UeOHHnmzJkzZ86kp6cfPXrUzc2t9mY//vjj2rVrN27cmJCQ\nMHbs2OsNc70dNRpNUz1eoC4CDaW5u7tHR0eHh4dv2bIlKytr586d0dHRU6ZM0Wg0w4cPX79+/c6d\nOwsLC19//fXw8PAGXsAOHTp069at8fHx+q86RkZG1q1qdna2paWlRqPZu3fvZ599VlBQoD93ISIl\nJSW1N7ulHYEmoAPUVlNTs3Dhwp49e9rY2Pj6+r7//vuVlZX6q1avXu3v76/Vah9//PHs7GydTpeS\nkhIQEKC/tu5lnU73008/BQUF2djYDBgwIC0tTafTHT16NCQkRKfTFRQUDBw40MbGpm/fvj/99JOP\nj8/y5ct1Ol1kZKRWqz106FDt/dzSjkAjaXRN9D3/AICmxSkOAFAUgQYARRFoAFAUgQYARRFoAFAU\ngQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYARRFoAFAUgQYA\nRf1/LW+oNb61y0YAAAAASUVORK5CYII=\n",
       "prompt_number": 20,
       "text": [
        "<IPython.core.display.Image at 0x103533c50>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 18"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot18.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxN+eM/8HNb7m1P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\nAABJRU5ErkJggg==\n",
       "prompt_number": 21,
       "text": [
        "<IPython.core.display.Image at 0x103533d90>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 19"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot19.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1xUdf748ffAAAIz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\n",
       "prompt_number": 22,
       "text": [
        "<IPython.core.display.Image at 0x103533dd0>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "##Graph 20"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename='./visualizations/plot20.png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVxN+eM/8HPr1m3f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\ngKFQ0AAADPX/AG2isPlqsFzLAAAAAElFTkSuQmCC\n",
       "prompt_number": 23,
       "text": [
        "<IPython.core.display.Image at 0x103533cd0>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
