{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Google Trends and Stock Prices\n",
      "\n",
      "Jordeen Chang, Anshuman Dewangan, Anirudh Kilambi, Hiroto Udagawa  \n",
      "STAT 133  \n",
      "Professor Benoit Dherin  \n",
      "4 May 2014\n",
      "\n",
      "###*Insert trends_logo.png\n",
      "###*Insert stocks_logo.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###Contributors\n",
      "\n",
      "* Anshuman Dewangan: Authored IPython Notebook from start to the end of Data Gathering section."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Introduction\n",
      "###*insert ben_0.jpg  \n",
      "You are Luc L'Argent, an investment banker who is looking to beat the stock market. You just took STAT 133 with Professor Dherin (who looks weirdly similar to you) and want to use statistical programming to develop a stock trading algorithm. However, you don't know about Time Series, Markov Chains, or other advanced trading tactics. What should you do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Luckily, you run across the following research paper:  \n",
      "###*Insert research_paper.jpg\n",
      "The paper investigates the extent to which investor opinions posted on social media predict future stock returns. The following quote catches your eye...\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1807265"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###\"A trading strategy based on social media sentiment could generate significant trading profits.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This gives you a great idea: What if you could use Google search data to predict future stock returns? You call your friends Bob, Marthieux, and Isabel from your STAT 133 class to do a data analysis project based on the idea."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##The Idea\n",
      "\n",
      "We want to analyze the relationship between Google Trends search data and stock prices for the companies in the Dow Jones Industrial Average, a list of 30 top U.S. companies, and the S&P500, a list of 500 top U.S. companies. We will look for three main trends:\n",
      "\n",
      "1. Relationship between Google Trends data for the company name/ticker (\u201cApple\u201d or \u201cAAPL\u201d) and the stock price.\n",
      "2. Relationship between Google Trends data for positive terms related to the company name/ticker (\u201cBuy Apple\u201d) and the stock price.\n",
      "3. Relationship between Google Trends data for negative terms related to the company name/ticker (\u201cSell Apple\u201d) and the stock price.\n",
      "\n",
      "Finally, we will make a simple stock trading algorithm based on these trends and see how a hypothetical portfolio would function on historical data. Excited? Great! Let's walk through the steps needed to complete the project, beginning with data gathering."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - Google Trends Website\n",
      "\n",
      "You call your friends over for help, but they have no idea where to begin. Let's see how we can get Google search data for a particular company, \"Apple.\" We'll Google \"google search data\" and see what we get!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "###*Insert google_search_data.jpg\n",
      "\n",
      "Ok, the first search result, \"Google Trends\" seems promising. Let's check it out!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "###*Insert google_trends.jpg\n",
      "\n",
      "Cool! Looks like we can enter different search terms and get some Google search data. Let's try it out for Apple."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "##*Insert download_csv.jpg\n",
      "\n",
      "Entering \"apple\" into the search box results in a graph of the search data over time. This is exactly what we want! And it seems like we can just \"Download as csv\" as well, making data gathering a breeze.  \n",
      "\n",
      "There's a lot of spikes and dips in the data; hopefully the variability in the search data will match the changes in Apple's stock price. We'll worry about that in the data analysis. But first, we have to pull the data in our iPython Notebook."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - Search Queries\n",
      "\n",
      "We want to get search data for a lot of different queries, so let's organize the information. First, we can manually create two csv files, \"SP500.csv\" and \"DowJones.csv,\" with the list of companies in the S&P500 and Dow Jones Industrial Average from Yahoo Finance with two columns: \"Company\", \"Ticker.\" This will allow us to easily generate queries for each company."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Queries can be categorized in many different ways:\n",
      "\n",
      "1. Company name\n",
      "2. Ticker symbol\n",
      "3. \"Buy\" + ticker symbol\n",
      "4. \"Sell\" + ticker symbol\n",
      "5. \"Buy\" + company name\n",
      "6. \"Sell\" + company name\n",
      "\n",
      "For example, Apple will have six different queries:\n",
      "\n",
      "1. Apple\n",
      "2. AAPL\n",
      "3. Buy AAPL\n",
      "4. Sell AAPL\n",
      "5. Buy Apple\n",
      "6. Sell Apple"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In our code, we'll create a class that takes in different types of queries for each company. The input will be the following arguments: \"company,\" \"ticker,\" \"'buy ' + ticker,\" \"'sell ' + ticker,\" \"'buy ' + company,\" \"'sell ' + company.\" The output will be a list of lists with all the search terms we want. We can later access different items in the list for different queries."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "--------------------------------\n",
      "##Data Gathering - A Look Into Google Trends Data\n",
      "\n",
      "Let's run some code that manipulates the Google Trends url to pull the data for \"Apple.\" First, we'll put the query into a form the browser will understand: with \"%20\" between each word. Then, we will append the search to a base Google Trends url to get a csv of the Google Trends data.  \n",
      "\n",
      "We'll use the following url, which seems to directly link us to the csv file:\n",
      "\n",
      "http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "file = read.csv(\"http://www.google.com/trends/trendsReport?hl=en-US&q=apple&cmpt=q&content=1&export=1\")\n",
      "print(file)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error in file(file, \"rt\") : cannot open the connection\n",
        "In addition: Warning message:\n",
        "In file(file, \"rt\") : unable to resolve 'www.google.com'\n",
        "Error in file(file, \"rt\") : cannot open the connection\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Looks like we got an error! :( After doing some research about Google Trends, we make a couple of findings:\n",
      "\n",
      "1. The data is not directly downloadable from a csv url\n",
      "2. The data is only securely available to Google users\n",
      "\n",
      "And we thought this was going to be easy! These problems arise because Google Trends has no API that allows users to pull data easily, making our lives much harder. Therefore, we have create a virtual browser that would allow us to pull csv files directly by authenticating Google using login credentials. Otherwise, there is no direct way to download the csv data through programming code. For ideas on how to do this, we conducted a lot of research and got some major help from our sources."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://gist.github.com/tlmaloney/5650699"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot of hard work...  \n",
      "###Insert hard_work.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We can create a virtual browser that makes it seem like we are users logged into Google. Google figured out we were a \"robot,\" so we had to add a line that bypasses this security. We even had to login to Google using our email (\"DherintoR\") and our password (\"forthestars\"). This will allow us to download the csv file that we wanted! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "After writing some more code, we can download a file that looks like this:\n",
      "###*Insert apple_csv.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Interesting, the csv file comes with a lot of junk information. Additionally, the actual Google Trends data comes in an awkward format: \"Date (given as a weekly range), \"Google Trends Value.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/answer/4365533?hl=en&ref_topic=4365599"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "After a lot more code, we'll clean the data so that it only saves the date for the Friday of each week (so we can easily obtain the corresponding stock prices) and puts all the information into two different lists: \"dates\" and \"values.\" Now the csv looks like this:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_half.jpg\n",
      "Okay! Now we just have to add in a column for stock price data and we'll be good to go :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "##Data Gathering - Explanation of Google Trends Data\n",
      "\n",
      "Before we continue, however, let's take a break and explain how the Google Trends data works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####How Trends Data is Normalized\n",
      "The Google Trends data for any particular query is normalized on a scale of 0-100, with \"100\" being the day that received the highest search volume. According to the Google Trends help page, \"Normalized means that sets of search data are divided by a common variable, like total searches, to cancel out the variable's effect on the data.\" "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "####Data that is Excluded\n",
      "Google is very protective over its search data, which is why it does not provide the original data but normalized values. Additionally, Google Trends does not provide information for the following data:\n",
      "\n",
      "1. \"Searches made by few people: Trends only analyzes data for popular search terms, so terms with low volume won\u2019t appear.\"\n",
      "2. \"Duplicate searches: Trends eliminates repeated queries from a certain user over a short period of time.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "####Problems with Google Trends Data\n",
      "With this information about Google Trends Data in mind, we run into three large problems. \n",
      "\n",
      "1. Data is only available weekly (for high volume search terms only) or monthly (for all other search terms) starting from January 2004 when Google began. This limits the number of data points we have access to. To increase the likelihood that we will retrieve search data, we created another file called \"DowJones_Modified.csv\" in which we manually changed company names to incorporate more popular search terms. For example, we would use \"Apple\" instead of \"Apple Inc.\" to get more search results.\n",
      "2. We cannot pull data for \"unpopular\" search terms. This limits the search terms that are effective for many of our companies. For example, while \"Apple\" retrieves data, \"sell CSCO\" returns a csv with blank data. We will avoid pulling data for these queries in our final data gathering script.\n",
      "3. Since the data is normalized, any time period with significantly less searches compared to other months will return a \"0\". Since the search volume grows over time, a lot of the data in the early years (2004-2007) just has zeroes for values. We will remove these data points during data cleaning.\n",
      "\n",
      "Due to these unavoidable biases, we take our conclusions with a grain of salt. However, these problems should not get in the way of finding the general relationship between search data and stock price, so let's push forward!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://support.google.com/trends/?hl=en"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "----------------------------------\n",
      "##Data Gathering - Stock Data\n",
      "\n",
      "Fortunately, getting stock data is much easier than getting Google Trends data, as we can use the Yahoo Finance API to pull the csv file direcly by manipulating the following url: http://ichart.yahoo.com/table.csv?s=AAPL&a=01&b=01&c=2004&d=00&e=00&f=0000&g=d&ignore=.csv.  \n",
      "\n",
      "The result is a csv file with the following information:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Source: https://code.google.com/p/yahoo-finance-managed/wiki/csvHistQuotesDownload"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "###*Insert apple_stock.jpg\n",
      "\n",
      "Great! We have daily stock data for Apple (AAPL) from from January 1, 2004 (when Google Trends data begins) to present. However, since Google Trends data is weekly or monthly, we don't need all these prices! We only want to use the closing prices for the corresponding dates from the Google Trends data, which should be the Friday of the week. What should we do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "There were many ways to approach this problem:\n",
      "\n",
      "1. For each date in \"dates,\" pull the stock price data from Yahoo Finance each time.\n",
      "2. Create a dictionary that maps \"date\" to \"closing price\" and use that to pull the appropriate prices.\n",
      "\n",
      "The first method made the code run very very slowly. After many many tries, we finally got a variation of the second method to work quickly. We'll put this information in a third list called \"prices.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Another problem we encountered was that stock data is not available from 2004-present for all stocks. This would make the \"dates\" list and the \"prices\" list of different lengths. We solved this by inputting a blank value, \"\", every time there wasn't stock price data available."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Lastly, some of the links to the stock data url were broken, preventing our code from completing. We added a \"try/except\" command to our code to continue with the data gathering even if there was an error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------------------\n",
      "##Data Gathering - Writing the Final CSV\n",
      "\n",
      "Fantastic! Now we have three lists with corresponding data:\n",
      "\n",
      "1. dates - Dates\n",
      "2. values - Google Trends values\n",
      "3. prices - Stock prices\n",
      "\n",
      "What's important to note is that the Google Trends value in \"values[0]\" and the stock price in \"prices[0]\" corresponds to the date in \"dates[0]\". This fact is crucial when executing the last step, which is to write a csv file containing all these values in separate columns: \"Date\", \"Value\" (header is denoted by the query term), and \"Price\". The csv file will be saved as \"Apple_gtrends.csv\" in the \"data/raw\" directory. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "We created a loop for each company and a loop for each query related to the company to get it to automate the process for all companies. After running the code successfully a few times, we quickly figured out that Google had a limit to queries: 1000 every 24 hours per Google account. After using different Google accounts, we even managed to get our IP address banned! Through sheer dedication, we were finally able to retrieve all the data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "This is what the final code looks like. Luc, you should be proud of all your hard work!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Downloads Google Trends and stock data for search terms related to companies in the Dow Jones Index. \n",
      "\n",
      "Creates a csv file with \"Date\", \"Google Trends value\", and \"Price\" for each search term.\n",
      "\n",
      "Files will be saved in the \"../data/raw/Data_Modified\" directory.\n",
      "\n",
      "Make sure to run \"sudo pip install mechanize\" before running the code for the first time.\n",
      "\n",
      "Data Sources: Google Trends (www.google.com/trends). Yahoo Finance (www.finance.yahoo.com).\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Imports all important modules for the program\n",
      "import sys\n",
      "import datetime\n",
      "import pandas\n",
      "import csv\n",
      "import cookielib\n",
      "import mechanize\n",
      "import re\n",
      "from StringIO import StringIO\n",
      " \n",
      "    \n",
      "# Reads \"DowJones_Modified.csv\" of stocks and ticker symbols into a pandas dataframe\n",
      "def stocks_data(data='../data/DowJones_Modified.csv'):\n",
      "    stocks = pandas.read_csv(data)\n",
      "    company = stocks.Company\n",
      "    ticker = stocks.Ticker\n",
      "    return stocks, company, ticker\n",
      "stocks, companies, tickers = stocks_data()\n",
      "\n",
      "\n",
      "# Creates a list of lists with search terms for all companies in the format given by inputs\n",
      "def query(*arg):\n",
      "    queries = []\n",
      "    for query in arg:\n",
      "        queries.append([query[n] for n in range(0, len(stocks))])\n",
      "    return queries       \n",
      "queries = query(companies, tickers, \"buy \" + tickers, \"sell \" + tickers, \"buy \" + companies, \"sell \" + companies)\n",
      "\n",
      "\n",
      "# Sets up a virtual browser to download Google Trends and stock data\n",
      "br = mechanize.Browser()\n",
      "def browser_setup():\n",
      "    # Open browser\n",
      "    br.set_handle_robots(False)\n",
      "    \n",
      "    # Create cookie jar\n",
      "    cj = cookielib.LWPCookieJar()\n",
      "    br.set_cookiejar(cj)\n",
      "    \n",
      "    # Act like we're a real browser\n",
      "    br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
      "    \n",
      "    # Login in to Google\n",
      "    response = br.open('https://accounts.google.com/ServiceLogin?hl=en&continue=https://www.google.com/')\n",
      "    forms = mechanize.ParseResponse(response)\n",
      "    form = forms[0]\n",
      "    form['Email'] = \"DherintoR\"\n",
      "    form['Passwd'] = \"forthestars\"\n",
      "    response = br.open(form.click())\n",
      "browser_setup()\n",
      "\n",
      "\n",
      "# Pulls Yahoo Finance stock data for given ticker from 2004-present\n",
      "def yahoo_finance(ticker_symbol):\n",
      "    base_url = \"http://ichart.yahoo.com/table.csv?s=\"\n",
      "    dt_url = '%s&a=%s&b=%s&c=%s&d=%s&e=%s&f=%s&g=d&ignore=.csv'% (ticker_symbol, \"01\", \"01\", \"2004\", \"00\", \"00\", \"0000\")\n",
      "    return base_url + dt_url\n",
      "\n",
      "    \n",
      "# Create CSV for each stock in stocks list\n",
      "for n in range(0,len(companies)):\n",
      "    \n",
      "    # Get stock data for the stock\n",
      "    url = yahoo_finance(tickers[n])\n",
      "    # Opens the Yahoo Finance csv file\n",
      "    response1 = br.open(url)\n",
      "    reader1 = csv.reader(StringIO(response1.read()))\n",
      "    # Creates a dictionary that maps dates to closing prices for that day\n",
      "    prices_dict = {row[0]: row[4] for row in reader1}\n",
      "\n",
      "    for x in range(0,len(queries)):\n",
      "        \n",
      "        # Split queries list into a format that can be entered into the url                \n",
      "        query_split = queries[x][n].split()\n",
      "        query_params = '%20'.join(query_split)\n",
      "        \n",
      "        # Get CSV from Google Trends\n",
      "        response = br.open('http://www.google.com/trends/trendsReport?hl=en-US&q=' + query_params + '&cmpt=q&content=1&export=1') \n",
      "        reader = csv.reader(StringIO(response.read()))\n",
      "        \n",
      "        # Creates empty lists to be populated with data\n",
      "        dates = []\n",
      "        values = []\n",
      "        prices = []\n",
      "        \n",
      "        # Populate lists with dates and Google Trends values in the correct formate.\n",
      "        for row in reader:\n",
      "            # Looks for the right rows to get data from, ignoring the junk\n",
      "            try:\n",
      "                date, value = row\n",
      "            except ValueError:\n",
      "                continue\n",
      "            # Takes the date for the Friday of the week and puts it in the correct format\n",
      "            if re.search('[0-9]{4}-[0-9]{2}-[0-9]{2}', date):\n",
      "                dates.append(str((datetime.datetime.strptime(date[-10:], \"%Y-%m-%d\")-datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\"))) # Uses last date in time period\n",
      "                values.append(value)\n",
      "        \n",
      "        # Adds stock prices to the corresponding dates found in the Google Trends data\n",
      "        for date in dates:\n",
      "            # Tries to add the price for the date from the Google Trends data\n",
      "            try:\n",
      "                prices.append(prices_dict[date])\n",
      "            # Adds a blank value if the price is not available for the Google Trends date\n",
      "            except:\n",
      "                prices.append(\"\")\n",
      "\n",
      "        # Sets the filename as the query\n",
      "        filename = queries[x][n]\n",
      "        filename.replace(\" \", \"\")\n",
      "        \n",
      "        # Creates a file in \"data/raw/DowJones_Modified/\" and writes values from our three lists\n",
      "        if dates != []:\n",
      "            with open(\"../data/raw/DowJones_Modified/\" + filename + \"_gtrends.csv\", 'w') as file:\n",
      "                writer = csv.writer(file, lineterminator = '\\n')\n",
      "                # Writes a header row with the titles: Date, Query, Price\n",
      "                writer.writerow(['Date', queries[x][n], \"Price\"])\n",
      "                # Writes a row for each value of date, value, and price\n",
      "                for row in zip(dates, values, prices):\n",
      "                    writer.writerow(row)\n",
      "                # Closes and saves the file\n",
      "                file.close()\n",
      "        else:\n",
      "            print \"Failed to get data for \" + queries[x][n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "-------------\n",
      "##Data Cleaning - Conclusion\n",
      "\n",
      "Finally, let's take a look at the final csv:\n",
      "\n",
      "##Insert apple_raw.jpg"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Beautiful! The date, Google Trends data, and stock prices are all right there next to each other. The csv file can be easily loaded into an R dataframe for some data cleaning in the next step. Luc, you are on your way to becoming a billionaire! :)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
